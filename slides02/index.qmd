---
title: "Media Analysis of PSI-20 Companies"
subtitle: "Insights from News and Public Coverage"
author:
  - name: "Hugo Veríssimo"
    affiliation: "124348"
format:
  revealjs: 
    slide-number: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: ua.png
    css: mystyle.css
    theme: serif
    transition: slide
echo: true
---

```{r setup, include = FALSE}
# packages
library(dplyr)
library(knitr)
library(xtable)
library(reticulate)
```

```{python, include=FALSE}
import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime
```

## lembretes {.justify}

- meter codigo dos graficos?: NAO

- meter modulos usados

$\ $

- texto justificado

- tudo em ingles

- tlvz fazer ponte de onde se ficou no trabalho 1 para agora ?

## data04.parquet {.justify}

```{=html}
<style>
.dataframe {
  display: block;
  max-width: 100%;
  max-height: 75%; /* vertical scrolling */
  overflow-x: auto;
  overflow-y: auto;
  font-family: "SFMono-Regular", Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
  /*border: 1px solid #ddd; apply only to big dfs */
}

table {
  max-width: 100%;
  border-collapse: collapse;
}

th, td { /* th is about header*/
  padding: 8px 16px;
  border: 1px solid #ddd; /* Border between cells */
  text-align: left;
  vertical-align: middle;
  font-size: 16px;
}

thead th {
  background-color: rgba(128, 128, 128, 0.3);
  font-weight: bold;
}

tbody td:first-child {
  background-color: rgba(128, 128, 128, 0.3);
  font-weight: bold;
}
</style>
```

```{=html}
<table style="border: 1px solid #ddd;" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>aliases</th>
<th>news</th>
</tr>
<tr>
<th>companies</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<th>Banco Comercial Português</th>
<td>[Banco Comercial Português, BCP]</td>
<td>[{'ExtractedText': 'DN &nbsp; 13 de Setembro de 200...</td>
</tr>
<tr>
<th>Galp Energia</th>
<td>[Galp Energia, GALP]</td>
<td>[{'ExtractedText': 'RTP Galp reforça posição n...</td>
</tr>
<tr>
<th>EDP</th>
<td>[EDP, Energias de Portugal, Electricidade de P...</td>
<td>[{'ExtractedText': 'DN-Sinteses Negocios 9 de ...</td>
</tr>
<tr>
<th>Sonae</th>
<td>[Sonae, SON]</td>
<td>[{'ExtractedText': 'DN-Sinteses 5 de Março de ...</td>
</tr>
<tr>
<th>Mota-Engil</th>
<td>[Mota-Engil, EGL]</td>
<td>[{'ExtractedText': 'RTP Lucro da Mota-Engil so...</td>
</tr>
</tbody>
</table>
```

$\ $

```{python}
pd.read_parquet("data04.parquet").iloc[0,1][0].keys()
```


# NER and Sentiment Analysis {.justify}

## NER 

- Used the model `pt_core_news_sm` from `spacy` to extract:

  - "PER" - named entity that represents a person
  
  - "ORG" - named entity that represents a group or organization
  
  - "LOC" - named entity that indicates a specific place
  
  - "MISC" - named entity that doesn’t fit into the other categories
  
  - "NOUN" - part-of-speech tag that identifies a noun in the sentence

- Additionally, the model was not filtering certain meaningless words and expressions, requiring the implementation of specific rules to address this issue.

```{=html}
<div class="footer">
  /notebooks/04_NERandSent.ipynb
</div>
```


## Sentiment Analysis {.justify}

- The initial approach involved using the `pipeline` from `transformers`, but the models consistently failed to load, leading to the exploration of an alternative solution to bypass this issue.

- The solution involved using:

  - `deep_translator` to overcome language restrictions
  
  - `vaderSentiment` and `textblob` to extract the sentiment of the news

```{=html}
<div class="footer">
  /notebooks/04_NERandSent.ipynb
</div>
```

## data05.parquet

```{=html}
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>aliases</th>
<th>news</th>
<th>keywords</th>
</tr>
<tr>
<th>companies</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<th>Banco Comercial Português</th>
<td>[Banco Comercial Português, BCP]</td>
<td>[{'ExtractedText': 'DN &nbsp; 13 de Setembro de 200...</td>
<td>{'03 Mar': {'count': 2.0, 'date': {'201503': 2...</td>
</tr>
<tr>
<th>Galp Energia</th>
<td>[Galp Energia, GALP]</td>
<td>[{'ExtractedText': 'RTP Galp reforça posição n...</td>
<td>{'00h00': {'count': 7.0, 'date': {'201004': 1....</td>
</tr>
<tr>
<th>EDP</th>
<td>[EDP, Energias de Portugal, Electricidade de P...</td>
<td>[{'ExtractedText': 'DN-Sinteses Negocios 9 de ...</td>
<td>{'00h00': {'count': 4.0, 'date': {'201004': No...</td>
</tr>
<tr>
<th>Sonae</th>
<td>[Sonae, SON]</td>
<td>[{'ExtractedText': 'DN-Sinteses 5 de Março de ...</td>
<td>{'00h00': {'count': 3.0, 'date': {'201004': No...</td>
</tr>
<tr>
<th>Mota-Engil</th>
<td>[Mota-Engil, EGL]</td>
<td>[{'ExtractedText': 'RTP Lucro da Mota-Engil so...</td>
<td>{'15h30': {'count': 2.0, 'date': {'201509': 1....</td>
</tr>
</tbody>
</table>
```

$\ $

```{.python}
pd.read_parquet("data05.parquet")["news"].iloc[0][0].keys()
```
```{python, echo=FALSE}
print("dict_keys(['ExtractedText', 'linkToArchive', 'newsNER', 'newsProbability', 'newsSentiment', 'newsSource', 'tstamp'])")
```

## data05.parquet

```{.python}
pd.read_parquet("data05.parquet")["keywords"].iloc[0]['03 Mar'].keys()
```
```{python, echo=FALSE}
print("dict_keys(['count', 'date', 'filter', 'news', 'sentiment', 'source', 'type', 'weight'])")
```

- coluna news agr tem uma componente no dicionario de sentimentos para cada noticia e todas as palavras extraidas categorizadas ({"PER", "ORG", "LOC", "MISC", NOUN})

- coluna keywords é um dicionario com a contagem de palavras por exempresa, sentimento referente à mesma, tipo de categorias onde foi vista, contagem das datas onde foi vista, contagem da source

# Visualizations

## News Sources

```{=html}
<figure style="text-align: center;">
    <img src="newsSources.svg" alt="noticias por fonte" style="width: 100%;">
    <figcaption style="font-size: 0.45em; margin-top: -25px; margin-bottom: 25px;">Fig. x: Descricao bla bla.</figcaption>
</figure>
```

link para **newsSources v01.ipynb**

apesar de ter usado 30 sites, a maioria so tem noticias pós 2020, e alguns n têm respostas de todo


## Word Cloud

```{=html}
<figure style="text-align: center;">
    <img src="wordcloud bcp.svg" alt="wordcloud bcp" style="width: 100%;">
    <figcaption style="font-size: 0.45em; margin-top: -25px; margin-bottom: 25px;">Fig. x: Descricao bla bla.</figcaption>
</figure>
```

feito com **compWordcloud v01.ipynb**, tendo por base as palavras mais mencionadas

## Word Cloud

```{=html}
<figure style="text-align: center; display: grid; grid-template-columns: repeat(2, 1fr); gap: 10px;">
  <img src="wordcloud galp.svg" alt="wordcloud galp" style="width: 100%;">
  <img src="wordcloud edp.svg" alt="wordcloud galp" style="width: 100%;">
  <img src="wordcloud sonae.svg" alt="wordcloud galp" style="width: 100%;">
  <img src="wordcloud motaengil.svg" alt="wordcloud galp" style="width: 100%;">
</figure>
```


## preço acoes e sentimentos/qnt news

```{=html}
<figure style="display: flex; flex-direction: column; align-items: center; gap: 5px;">
  <div style="display: flex; flex-direction: row; gap: 5px;">
    <img src="newsVSsenti01.svg" alt="Image 1" style="width: 50%;" />
    <img src="newsVSsenti04.svg" alt="Image 2" style="width: 50%;" />
  </div>
  <figcaption style="font-size: 0.45em; margin-top: -25px; margin-bottom: 25px text-align: center;">GALP.LS, Galp Energia</figcaption>
</figure>
```

info = {1: "media dos sentimentos do mes",
        4: "mes se é positivo ou negativo",
        #5: "log da soma dos sentimentos do mes, pq Redução de Disparidades Extremas, Linearização da Relação",
        #6: "número de notícias do mês",
        #7: "número de notícias do mês, diferenciado",
        #8: "número de notícias do mês e varicao do preco em abs",
        #10: "numero de noticias do mes, mas em log",
        #11: "número de notícias do mês, diferenciado e em log",
        #12: "número de notícias do mês, diferenciado e dif de precos em exp",
        #13: "número de notícias do mês, diferenciado e em log",
        #14: "número de notícias do mês, diferenciado e dif de precos em %"
        }
        
- a meu ver, e de acordo com os coef de correlacao, n ha nenhuma corr entre qnt de noticias e variacao do preco...

- simplesmente n existe

- fiz mal os sentimentos

- tnh noticias irrelevantes


feito com **newsVSstock v02**

## Stock Price and Sentiment Analysis

```{=html}
<div style="text-align: center;">
  <iframe src="stockVSsenti bcp.html" width="100%" height="300"></iframe>
</div>
```

used **newsVSstock v04.ipynb**

api for stock price https://www.alphavantage.co

## Stock Price and Sentiment Analysis

```{=html}
<figure style="text-align: center; display: grid; grid-template-columns: repeat(2, 1fr); gap: 10px;">
  <iframe src="stockVSsenti galp.html" width="100%" height="300"></iframe>
  <iframe src="stockVSsenti edp.html" width="100%" height="300"></iframe>
  <iframe src="stockVSsenti sonae.html" width="100%" height="300"></iframe>
  <iframe src="stockVSsenti motaengil.html" width="100%" height="300"></iframe>
</figure>
```

## next

aa
