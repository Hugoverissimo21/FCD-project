{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**filtar dados: repetidos, muito semelhantes or inuteis**\n",
    "\n",
    "por termos usado `&dedupValue=25&dedupField=url` e diferentes aliases, há informação repetida\n",
    "\n",
    "problemas:\n",
    "\n",
    "- ~~API has the following usage limits (250req/min, error 429):~~ time.sleep(60)\n",
    "\n",
    "- ~~API error 404 for some urls:~~ return 0 (False) and skip it\n",
    "\n",
    "- ~~extrair demora muito tempo, erro dá cabo de tudo:~~\n",
    "\n",
    "- - funcao por coluna: inp: [col1, col2]: df03=02.copy, replace col, save, replace col, save...se der erro, só importa a ultima col\n",
    "\n",
    "- - se fizer de vez keywords/sentiment/... assim poupa-se tempo do 1min dos requests\n",
    "\n",
    "- noticias sobre algo, e contém a palavra Galp, como sei oq interessa?\n",
    "\n",
    "- 1. se resumir a noticia e n tiver a palavra galp, ignoro?\n",
    "\n",
    "- 2. selecionar frase que tem a palavra +-1 frase, e pronto ?\n",
    "\n",
    "- 3. ?\n",
    "\n",
    "- filtrar noticias muito parecidas\n",
    "\n",
    "- 1. fazer NER, dois iguais, ver se é 80% igual?\n",
    "\n",
    "- 2. selecionar 4 frases aleatórias ou contar palavras, e se for igual pronto?\n",
    "\n",
    "\n",
    "tentar NER + Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_with_retry(linkToExtractedText):\n",
    "    # Infinite loop to handle retry logic in case of 429 Too Many Requests\n",
    "    while True:\n",
    "        response = requests.get(linkToExtractedText)\n",
    "        status_code = response.status_code\n",
    "        \n",
    "        if status_code == 200:\n",
    "            # If the request is successful (200 OK), return the extracted text\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            return soup.get_text()\n",
    "        elif status_code == 429:\n",
    "            # Handle 429 Too Many Requests by reading the Retry-After header\n",
    "            print(f\"Too many requests. Retrying after {60} seconds...\")\n",
    "            time.sleep(60)  # Pause execution for the retry period\n",
    "        elif status_code == 404:\n",
    "            return 0\n",
    "        else:\n",
    "            # For any other status codes (e.g., 500, ...), print the status and break the loop\n",
    "            print(f\"Request failed with status code {status_code}. Link was {linkToExtractedText}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Function to process each column\n",
    "def process_cell(column, aliases):\n",
    "\n",
    "    stats = {\"404\": 0, \"duplicate\": 0}\n",
    "\n",
    "    filtered_column = []\n",
    "\n",
    "    for row in aliases.index:\n",
    "        filtered_cell = []\n",
    "        seen_text = set()\n",
    "        print(f\"{row}\", end = \"; \")\n",
    "        for i in column.loc[row]:\n",
    "            \n",
    "            # Extract text from 'linkToExtractedText'\n",
    "            text = fetch_with_retry(i['linkToExtractedText'])\n",
    "                \n",
    "\n",
    "            # Skip if the text has already been processed\n",
    "            if text in seen_text:\n",
    "                stats[\"duplicate\"] += 1\n",
    "                continue\n",
    "\n",
    "            elif not text: #ERROR 404\n",
    "                stats[\"404\"] += 1\n",
    "                continue\n",
    "            \n",
    "            # Check if any alias is found in the text\n",
    "            elif any(alias.lower() in text.lower() for alias in aliases.loc[row]):\n",
    "                i[\"ExtractedText\"] = text  # Add extracted text to the record\n",
    "                \n",
    "                # Remove unwanted fields\n",
    "                i.pop('title', None)\n",
    "                i.pop('snippet', None)\n",
    "                i.pop('linkToExtractedText', None)\n",
    "                \n",
    "                # Append the processed record\n",
    "                filtered_cell.append(i)\n",
    "                \n",
    "                # Mark this text as processed\n",
    "                seen_text.add(text)\n",
    "\n",
    "        filtered_column.append(filtered_cell)\n",
    "                \n",
    "    return filtered_column, stats\n",
    "\n",
    "\n",
    "df = pd.read_parquet(\"data02.parquet\")\n",
    "\n",
    "\n",
    "start_time = datetime.now()\n",
    "print(f\"Starting: {start_time}\")\n",
    "for column in df.columns:\n",
    "    if column == \"aliases\":\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"\\nProcessing {column}\", end = \": \")\n",
    "        df[column], stats = process_cell(df[column], df[\"aliases\"])\n",
    "end_time = datetime.now()\n",
    "print(f\"Ended: {end_time}.\")\n",
    "print(stats)\n",
    "\n",
    "df.to_parquet(\"data03.parquet\")\n",
    "\"\"\"\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Alguns exemplos: Presidência do Conselho de Ministros, ministérios da Economia e das Finanças, Galp Energia, TAP, grupo EDP e RTP.  Refiram-se alguns exemplos sintomáticos: Presidência do Conselho de Ministros, ministérios da Economia e das Finanças, Galp Energia, TAP, grupo EDP e RTP.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"data01.parquet\")\n",
    "\n",
    "text =  fetch_with_retry(df[\"api.2000\"].loc[\"Galp Energia\"][1][\"linkToExtractedText\"])\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_information(text, keyword):\n",
    "    # Compile a regex pattern to find whole sentences containing the keyword\n",
    "    pattern = re.compile(r'([^.]*?\\b' + re.escape(keyword) + r'\\b[^.]*\\.)', re.IGNORECASE)\n",
    "    \n",
    "    # Find all matches for the keyword in the text\n",
    "    matches = pattern.findall(text)\n",
    "    \n",
    "    # If matches are found, return them; otherwise, return an informative message\n",
    "    if matches:\n",
    "        return ' '.join(matches)\n",
    "    else:\n",
    "        return f\"No information found about {keyword}.\"\n",
    "\n",
    "# Example usage with your provided text\n",
    "\n",
    "extract_information(text, \"Galp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "galp = pd.read_parquet(\"data01.parquet\")[\"api.2000\"].loc[\"Galp Energia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DN-Suplementos Negócios 10 de Setembro de 2001 Agências nacionais \"esquecidas\" pelo Estado Prevenção Rodoviária não convidou empresas portuguesas para o seu concurso publicitário Cátia Almeida DN-Natacha Cardoso Em pé de igualdade. Agências nacionais são tão boas como as multinacionais, afirma António Ferreira A Prevenção Rodoviária Portuguesa (PPR) abriu um concurso com o objectivo de seleccionar uma agência para desenvolver a sua próxima campanha de publicidade. Só que, para participar no concurso, apenas foram convidadas empresas que fazem parte de cadeias multinacionais (oito), ficando de lado as agências portuguesas. Para António Ferreira, director de serviço a clientes da MKT (agência do grupo Central de Comunicação), é inadmissível que, \"num concurso com dinheiro dos contribuintes, as empresas nacionais não possam sequer apresentar uma proposta. Este caso, que não é único, ilustra uma atitude de preconceito para com aquilo que é nacional\". \"Há excelentes empresas portuguesas que deviam ser preferidas pelo Estado. Até porque são elas que geram riqueza ao País. O Estado não pode ser concorrente das empresas nacionais, mas sim um aliado.\" Mas, ao que parece, os organismos públicos ou empresas com uma forte participação estatal estão \"aliados\" a agências multinacionais. Alguns exemplos: Presidência do Conselho de Ministros, ministérios da Economia e das Finanças, Galp Energia, TAP, grupo EDP e RTP. Segundo António Ferreira, não há razão para as agências nacionais serem relegadas para segundo plano. \"A qualidade é igual. Há grande rotatividade dos criativos e os equipamentos tecnológicos, basicamente computadores, são semelhantes. Há capacidade, precisamos é de oportunidades.\" Contactada pelo DN, a PRP justificou a escolha das agências para o seu concurso por se tratarem das primeiras do ranking . \"Não temos nada contra as agências portuguesas. O nosso critério prendeu-se exclusivamente com o volume de negócios. Para nós, ser ou não ser nacional não constitui um critério. Não há preferência pelo que é português\", afirmou Maria Gabriel, do departamento de Publicidade e Relações Públicas. \"Já trabalhámos com agências portuguesas, mas, desta vez, por se tratar de uma campanha de maior dimensão, quisemos convidar as maiores empresas para termos mais margem de manobra. E, em princípio, os melhores criativos estão nas maiores agências\", acrescentou a interlocutora do DN. Quanto ao facto de se tratar de um organismo ligado ao Estado, a responsável da PRP argumentou: \"Somos uma associação privada, embora tenhamos subsídios públicos.\" O critério seguido pela PRP revela a não valorização daquilo que é nacional. \"Na maior parte dos países europeus são as agências nacionais que lideram os rankings . As grandes marcas preferem sempre as agências dos seus próprios países\", salientou António Ferreira. Mas em Portugal há também quem pense assim. Marcas como a Vista Alegre, Atlantis, Super Bock, Bolachas Triunfo, Cafés Delta e Banif são promovidas por empresas nacionais. E existem até grandes empresas estrangeiras, como a Nokia, Mercedes e Hyundai, que trabalham igualmente com agências portuguesas, apesar de muitas vezes seguirem uma estratégia de alinhamento. As contas Os organismos públicos ou empresas com uma forte participação estatal estão \"aliados\" a agências publicitárias multinacionais. Refiram-se alguns exemplos sintomáticos: Presidência do Conselho de Ministros, ministérios da Economia e das Finanças, Galp Energia, TAP, grupo EDP e RTP. Mas em Portugal há também quem prefira o que é nacional. Marcas como a Vista Alegre, Atlantis, Super Bock, Bolachas Triunfo, Cafés Delta e Banif são promovidas por empresas portuguesas. Existem até grandes empresas estrangeiras, como a Nokia, Mercedes e Hyundai, que trabalham igualmente com agências portuguesas, apesar de muitas vezes seguirem uma estratégia de alinhamento multinacional. De acordo com o \"ranking\" APAP, referente a 2000, quatro agências nacionais estão no \"top\" 20: Nova Publicidade (9), Strat (16), MKT (19) e Opal (20). No \"ranking\" da Sabatina 2000, que mede os investimentos a preços de tabela, a Strat está em 16.º lugar, a Nova Publicidade em 19.º e a MKT em 20.º. Copyright © 1995,2001 Diário de Notícias, SA Todos os direitos reservados webmaster@DnOnline\n",
      "Nenhuma informação relevante sobre a empresa foi encontrada.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from transformers import pipeline\n",
    "\n",
    "# Carregar o modelo de NLP do spaCy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "# Inicializar o pipeline de sumarização\n",
    "summarizer = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\", framework=\"pt\")\n",
    "\n",
    "\n",
    "# Função para extrair partes do texto relacionadas à empresa e gerar um resumo\n",
    "def extrair_resumo(texto, nome_empresa):\n",
    "    # Passo 1: Identificar entidades mencionadas no texto\n",
    "    doc = nlp(texto)\n",
    "    # Passo 2: Filtrar sentenças que mencionam a empresa\n",
    "    sentencas_relevantes = [sent.text for sent in doc.sents if nome_empresa.lower() in sent.text.lower()]\n",
    "    # ISTO FAZ COM Q SE IGNORE TUDO  O Q N DIZ GALP !!!!\n",
    "    \n",
    "    # Passo 3: Se encontrarmos sentenças relacionadas à empresa, concatenamos e fazemos um resumo\n",
    "    if sentencas_relevantes:\n",
    "        texto_relevante = \" \".join(sentencas_relevantes)\n",
    "        # Gerar um resumo a partir do texto relevante\n",
    "        resumo = summarizer(texto_relevante, max_length=len(texto_relevante)*0.5, min_length=30, do_sample=False) #max_length=100, min_length=30\n",
    "        return resumo[0]['summary_text']\n",
    "    \n",
    "    return \"Nenhuma informação relevante sobre a empresa foi encontrada.\"\n",
    "\n",
    "# Exemplo de uso\n",
    "#texto_exemplo = \"\"\"\n",
    "#A empresa X tem crescido no mercado de tecnologia. Ela recentemente fez uma parceria com a Y corp.\n",
    "#No entanto, alguns críticos dizem que o mercado global pode impactar negativamente. Em 2023, a empresa X lançou novos produtos no setor de IA.\n",
    "#\"\"\"\n",
    "\n",
    "df = pd.read_parquet(\"data01.parquet\")[\"api.2000\"].loc[\"Galp Energia\"]\n",
    "texto_exemplo = fetch_with_retry(df[0][\"linkToExtractedText\"])\n",
    "\n",
    "\n",
    "nome_empresa = \"Galp\"\n",
    "resumo = extrair_resumo(texto_exemplo, nome_empresa)\n",
    "print(resumo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Your max_length is set to 200, but your input_length is only 101. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Presidência do Conselho de Ministros, ministérios da Economia e das Finanças, Galp Energia, TAP, grupo EDP e RTP .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar o modelo de NLP do spaCy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "# Inicializar o pipeline de sumarização\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "# Função para extrair partes do texto relacionadas à empresa e gerar um resumo\n",
    "def extrair_resumo(texto, nome_empresa):\n",
    "    # Passo 1: Identificar entidades mencionadas no texto\n",
    "    doc = nlp(texto)\n",
    "    \n",
    "    # Passo 2: Filtrar sentenças que mencionam a empresa\n",
    "    sentencas_relevantes = [sent.text for sent in doc.sents if nome_empresa.lower() in sent.text.lower()]\n",
    "    # MESMO PROBLEMA DE SO PEGAR EM FRASES Q DIZEM GALP !! \n",
    "    \n",
    "    # Passo 3: Se encontrarmos sentenças relacionadas à empresa, concatenamos e fazemos um resumo\n",
    "    if sentencas_relevantes:\n",
    "        texto_relevante = \" \".join(sentencas_relevantes)\n",
    "        \n",
    "        # Gerar um resumo a partir do texto relevante\n",
    "        resumo = summarizer(texto_relevante, max_length=200, min_length=30, do_sample=False)\n",
    "        \n",
    "        return resumo[0]['summary_text']\n",
    "    \n",
    "    return \"Nenhuma informação relevante sobre a empresa foi encontrada.\"\n",
    "\n",
    "# Exemplo de uso com um DataFrame\n",
    "df = pd.read_parquet(\"data01.parquet\")[\"api.2000\"].loc[\"Galp Energia\"]\n",
    "\n",
    "# Obter o texto de uma URL ou fonte\n",
    "texto_exemplo = fetch_with_retry(df[0][\"linkToExtractedText\"])\n",
    "\n",
    "# Extrair o resumo\n",
    "nome_empresa = \"Galp\"\n",
    "resumo = extrair_resumo(texto_exemplo, nome_empresa)\n",
    "print(resumo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcdProj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
