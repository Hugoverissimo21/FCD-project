---
title: "Media Analysis of PSI-20 Companies"
subtitle: "Insights from News and Public Coverage"
author:
  - name: "Hugo Veríssimo"
    affiliation: "124348"
format:
  revealjs: 
    slide-number: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: ua.png
    css: mystyle.css
    theme: serif
    transition: slide
echo: true
---

```{r setup, include = FALSE}
# packages
library(dplyr)
library(knitr)
library(xtable)
library(reticulate)
```

```{python, include=FALSE}
import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime
import json
```

## NOTAS {.justify}

...

## data05.parquet {.justify}

```{=html}
<style>
.dataframe {
  display: block;
  max-width: 100%;
  max-height: 75%; /* vertical scrolling */
  overflow-x: auto;
  overflow-y: auto;
  font-family: "SFMono-Regular", Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
  /*border: 1px solid #ddd; apply only to big dfs */
}

table {
  max-width: 100%;
  border-collapse: collapse;
}

th, td { /* th is about header*/
  padding: 8px 16px;
  border: 1px solid #ddd; /* Border between cells */
  text-align: left;
  vertical-align: middle;
  font-size: 16px;
}

thead th {
  background-color: rgba(128, 128, 128, 0.3);
  font-weight: bold;
}

tbody td:first-child {
  background-color: rgba(128, 128, 128, 0.3);
  font-weight: bold;
}
</style>
```

```{=html}
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>aliases</th>
<th>news</th>
<th>keywords</th>
</tr>
<tr>
<th>companies</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<th>Banco Comercial Português</th>
<td>[Banco Comercial Português, BCP]</td>
<td>[{'ExtractedText': 'DN &nbsp; 13 de Setembro de 200...</td>
<td>{'03 Mar': {'count': 2.0, 'date': {'201503': 2...</td>
</tr>
<tr>
<th>Galp Energia</th>
<td>[Galp Energia, GALP]</td>
<td>[{'ExtractedText': 'RTP Galp reforça posição n...</td>
<td>{'00h00': {'count': 7.0, 'date': {'201004': 1....</td>
</tr>
<tr>
<th>EDP</th>
<td>[EDP, Energias de Portugal, Electricidade de P...</td>
<td>[{'ExtractedText': 'DN-Sinteses Negocios 9 de ...</td>
<td>{'00h00': {'count': 4.0, 'date': {'201004': No...</td>
</tr>
<tr>
<th>Sonae</th>
<td>[Sonae, SON]</td>
<td>[{'ExtractedText': 'DN-Sinteses 5 de Março de ...</td>
<td>{'00h00': {'count': 3.0, 'date': {'201004': No...</td>
</tr>
<tr>
<th>Mota-Engil</th>
<td>[Mota-Engil, EGL]</td>
<td>[{'ExtractedText': 'RTP Lucro da Mota-Engil so...</td>
<td>{'15h30': {'count': 2.0, 'date': {'201509': 1....</td>
</tr>
</tbody>
</table>
```

```{.python}
pd.read_parquet("data05.parquet")["news"].iloc[0][0].keys()
```
```{python, echo=FALSE}
print("dict_keys(['ExtractedText', 'linkToArchive', 'newsNER', 'newsProbability', 'newsSentiment', 'newsSource', 'tstamp'])" +"\n ")
```

```{.python}
pd.read_parquet("data05.parquet")["keywords"].iloc[0]['03 Mar'].keys()
```
```{python, echo=FALSE}
print("dict_keys(['count', 'date', 'filter', 'news', 'sentiment', 'source', 'type', 'weight'])")
```

## Optimized Data Storage {.justify}

Optimized data organization by saving each cell as a separate JSON file, enhancing loading speed and flexibility.

**news_{company}.json**

```{.python}
json.load(open("news_bcp.json")); .keys()[0] & .values()[0].keys()
```

```{python, echo=FALSE}
print("'https://arquivo.pt/noFrame/replay/20010913052557/http://www.dn.pt/int/13p4x.htm'")
print("dict_keys(['keywords', 'probability', 'sentiment', 'source', 'tstamp'])\n ")
```


**kwrd_{company}.json**

```{.python}
json.load(open("kwrd_bcp.json")); .keys()[:3] & .values()[0].keys()
```

```{python, echo=FALSE}
print("['03 Mar', '10 Nov', '100 Segundos de Ciência']")
print("dict_keys(['count', 'date', 'filter', 'news', 'sentiment', 'source', 'type', 'weight'])")
```

```{=html}
<div class="footer">
  /notebooks/06_DataToJson.ipynb
</div>
```

## News Recommendation System {.justify}

`TfidfVectorizer()` and `cosine_similarity` from `scikit-learn` were used to compute the similarity between news articles.

```{=html}
<figure style="text-align: center">
    <img src="newsDendrogram.svg" alt="cluster de noticias" style="width: 95%;">
</figure>
```

```{=html}
<div class="footer">
  /tests/newsCluster v04.ipynb
</div>
```


## News Recommendation System {.justify}

```{.python}
iteration = 0
ratings = np.array([3.0] * len(news))


def news_recommendation(ratings):
  global iteration
  iteration += 1
  
  # The exponential assigns higher probabilities to larger values 
  weights = np.exp(np.array(ratings)) / weights.sum()
  
  # Select the next suggestion based on the weights
  news_i = np.random.choice(len(news), p = weights)
  
  return news_i


def update_ratings(news_i, user_rating):
    global ratings
    global iteration
    learning_rate = 0.999 * iteration
    
    # Compute similarity to all other texts
    similarity_scores = cosine_similarity(tfidf[news_i], tfidf).flatten()
    
    # Update the ratings for all news
    ratings += (user_rating - ratings) * similarity_scores * learning_rate
    ratings[news_i] = -1000
```

```{=html}
<div class="footer">
  /tests/newsCluster v04.ipynb
</div>
```

## News Recommendation System {.justify}

```{=html}
<figure style="text-align: center; ; margin-top:0px">
    <img src="newsRatings.png" alt="rating de noticias" style="width: 100%;">
</figure>
```

```{=html}
<div class="footer">
  /tests/newsCluster v04.ipynb
</div>
```

## hilo

http://www.higherlowergame.com

https://noticioso.pt

random choise of keywords, user has to say higher or lower, and check if its correct

```{=html}
<div class="footer">
  /tests/keysHiLo v01.ipynb
</div>
```

## where everything comes thogether

https://hugover.pythonanywhere.com

## photos / gifs for each tab

photos or gifs or videos of the site working, just in case something goes wrong, use local host since its faster. can only do when site is finished

