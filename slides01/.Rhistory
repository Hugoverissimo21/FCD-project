import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime
pd.read_parquet("data04.parquet").iloc[0,1][0]
pd.read_parquet("data04.parquet").iloc[0,1][0]
import json
import unicodedata
def normalize_text(text):
# Normalize to NFKD and then encode to ASCII ignoring errors
normalized = unicodedata.normalize('NFKD', text)
return normalized.encode('ASCII', 'ignore').decode('utf-8')
# Your original dictionary
dict = pd.read_parquet("data04.parquet").iloc[0,1][0]
data = {"tstamp": dict["tstamp"], "newsProbability": dict["newsProbability"], 'newsSource': dict['newsSource'],
"linkToArchive": dict["linkToArchive"],
"ExtractedText": normalize_text(dict["ExtractedText"])[:270] + "..."}
# Convert to JSON string with separators
pretty_json_string = json.dumps(data, indent=4)
# Print the JSON string
print(pretty_json_string), print(len(dict))
import json
import unicodedata
def normalize_text(text):
# Normalize to NFKD and then encode to ASCII ignoring errors
normalized = unicodedata.normalize('NFKD', text)
return normalized.encode('ASCII', 'ignore').decode('utf-8')
# Your original dictionary
dict = pd.read_parquet("data04.parquet").iloc[0,1][0]
data = {"tstamp": dict["tstamp"], "newsProbability": dict["newsProbability"], 'newsSource': dict['newsSource'],
"linkToArchive": dict["linkToArchive"],
"ExtractedText": normalize_text(dict["ExtractedText"])[:270] + "..."}
# Convert to JSON string with separators
pretty_json_string = json.dumps(data, indent=4)
# Print the JSON string
print(pretty_json_string)
