import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime
import json
import unicodedata
def normalize_text(text):
# Normalize to NFKD and then encode to ASCII ignoring errors
normalized = unicodedata.normalize('NFKD', text)
return normalized.encode('ASCII', 'ignore').decode('utf-8')
# Your original dictionary
dict = pd.read_parquet("data03.parquet").iloc[0,1][0]
print(dict.keys)
data = {"tstamp": dict["tstamp"],
"linkToArchive": dict["linkToArchive"],
"ExtractedText": normalize_text(dict["ExtractedText"])}
# Convert to JSON string with separators
pretty_json_string = json.dumps(data, indent=4)
# Print the JSON string
print(pretty_json_string)
import json
import unicodedata
def normalize_text(text):
# Normalize to NFKD and then encode to ASCII ignoring errors
normalized = unicodedata.normalize('NFKD', text)
return normalized.encode('ASCII', 'ignore').decode('utf-8')
# Your original dictionary
dict = pd.read_parquet("data03.parquet").iloc[0,1][0]
print(dict.keys())
data = {"tstamp": dict["tstamp"],
"linkToArchive": dict["linkToArchive"],
"ExtractedText": normalize_text(dict["ExtractedText"])}
# Convert to JSON string with separators
pretty_json_string = json.dumps(data, indent=4)
# Print the JSON string
print(pretty_json_string)
import json
import unicodedata
def normalize_text(text):
# Normalize to NFKD and then encode to ASCII ignoring errors
normalized = unicodedata.normalize('NFKD', text)
return normalized.encode('ASCII', 'ignore').decode('utf-8')
# Your original dictionary
dict = pd.read_parquet("data03.parquet").iloc[0,1][0]
#print(dict.keys())
data = {"newsProbability": dict["newsProbability"],"tstamp": dict["tstamp"],
"linkToArchive": dict["linkToArchive"],
"ExtractedText": normalize_text(dict["ExtractedText"])}
# Convert to JSON string with separators
pretty_json_string = json.dumps(data, indent=4)
# Print the JSON string
print(pretty_json_string)
import json
import unicodedata
def normalize_text(text):
# Normalize to NFKD and then encode to ASCII ignoring errors
normalized = unicodedata.normalize('NFKD', text)
return normalized.encode('ASCII', 'ignore').decode('utf-8')
# Your original dictionary
dict = pd.read_parquet("data03.parquet").iloc[0,1][1]
#print(dict.keys())
data = {"newsProbability": dict["newsProbability"],"tstamp": dict["tstamp"],
"linkToArchive": dict["linkToArchive"],
"ExtractedText": normalize_text(dict["ExtractedText"])}
# Convert to JSON string with separators
pretty_json_string = json.dumps(data, indent=4)
# Print the JSON string
print(pretty_json_string)
import json
import unicodedata
def normalize_text(text):
# Normalize to NFKD and then encode to ASCII ignoring errors
normalized = unicodedata.normalize('NFKD', text)
return normalized.encode('ASCII', 'ignore').decode('utf-8')
# Your original dictionary
dict = pd.read_parquet("data03.parquet").iloc[0,1][1]
#print(dict.keys())
data = {"newsProbability": dict["newsProbability"],"tstamp": dict["tstamp"],
"linkToArchive": dict["linkToArchive"],
"ExtractedText": normalize_text(dict["ExtractedText"])}
# Convert to JSON string with separators
pretty_json_string = json.dumps(data, indent=4)
# Print the JSON string
print(pretty_json_string)
