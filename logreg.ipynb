{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i need to create a dataset to train my logistical regression on\n",
    "\n",
    "i want the following features:\n",
    "\n",
    "- how many times appears the aliases\n",
    "\n",
    "- proportion of alphanumeric char\n",
    "\n",
    "- size of the text\n",
    "\n",
    "- others ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aliases</th>\n",
       "      <th>api.2000</th>\n",
       "      <th>api.2003</th>\n",
       "      <th>api.2006</th>\n",
       "      <th>api.2009</th>\n",
       "      <th>api.2012</th>\n",
       "      <th>api.2015</th>\n",
       "      <th>api.2018</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>companies</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Banco Comercial Português</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>191</td>\n",
       "      <td>169</td>\n",
       "      <td>497</td>\n",
       "      <td>983</td>\n",
       "      <td>1219</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Galp Energia</th>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>233</td>\n",
       "      <td>181</td>\n",
       "      <td>469</td>\n",
       "      <td>964</td>\n",
       "      <td>1104</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDP</th>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>245</td>\n",
       "      <td>140</td>\n",
       "      <td>538</td>\n",
       "      <td>1076</td>\n",
       "      <td>1528</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sonae</th>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>318</td>\n",
       "      <td>239</td>\n",
       "      <td>459</td>\n",
       "      <td>1109</td>\n",
       "      <td>1400</td>\n",
       "      <td>1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mota-Engil</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>26</td>\n",
       "      <td>164</td>\n",
       "      <td>384</td>\n",
       "      <td>596</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           aliases  api.2000  api.2003  api.2006  api.2009  \\\n",
       "companies                                                                    \n",
       "Banco Comercial Português        2        90       191       169       497   \n",
       "Galp Energia                     2        66       233       181       469   \n",
       "EDP                              3        80       245       140       538   \n",
       "Sonae                            2       130       318       239       459   \n",
       "Mota-Engil                       2         3        67        26       164   \n",
       "\n",
       "                           api.2012  api.2015  api.2018  \n",
       "companies                                                \n",
       "Banco Comercial Português       983      1219       824  \n",
       "Galp Energia                    964      1104       812  \n",
       "EDP                            1076      1528       872  \n",
       "Sonae                          1109      1400      1026  \n",
       "Mota-Engil                      384       596       445  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"data02.parquet\")\n",
    "df.map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's use bcp, 2003 to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = df.iloc[0,0]\n",
    "texts = [i[\"ExtractedText\"] for i in df.iloc[0,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_alises(aliases, text):\n",
    "    alias_count = {expression: 0 for expression in aliases}\n",
    "    for alias in aliases:\n",
    "        # Use re.escape to handle any special characters in the expression\n",
    "        pattern = re.escape(alias.lower())\n",
    "        matches = re.findall(pattern, text.lower())\n",
    "        alias_count[alias] = len(matches)\n",
    "    return sum(alias_count.values())\n",
    "\n",
    "def proportion_alphanumeric(text):\n",
    "    alphanumeric_chars = sum(char.isalnum() for char in text)\n",
    "    proportion = alphanumeric_chars / len(text)\n",
    "    return proportion\n",
    "\n",
    "def count_dates(text):\n",
    "    date_pattern = r'\\b(\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}|\\d{4}[-/]\\d{1,2}[-/]\\d{1,2})\\b'\n",
    "    # 10/11/2024', '10/10/2024', '12-25-1990', '2024-11-05', '01/10/2024'\n",
    "    dates = re.findall(date_pattern, text)\n",
    "    date_count = len(dates)\n",
    "    return date_count\n",
    "\n",
    "def count_CAPS(text):\n",
    "    words = text.split()\n",
    "    uppercase_word_count = sum(1 for word in words if word.isupper())\n",
    "    return uppercase_word_count\n",
    "\n",
    "def text_size(text):\n",
    "    return len(text)\n",
    "\n",
    "def Ist_ocurrence(text, aliases):\n",
    "    indexs = []\n",
    "    for alias in aliases:\n",
    "        index = text.lower().find(alias.lower())\n",
    "        if index != -1:\n",
    "            indexs.append(index)\n",
    "    return text[:min(indexs)].count(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets start creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_create(aliases, texts, out_name):\n",
    "    dic = {\"news\": [], \"countALI\": [], \"IstALIAS\": [], \"propAN\": [], \"countDTS\": [], \"txtSZ\": [], \"countCAPS\": [], \"txt\": []}\n",
    "    i = 0 \n",
    "    #global a\n",
    "    random.shuffle(texts)\n",
    "    for text in texts:\n",
    "        valid = int(input(text))\n",
    "        #valid = int(a[i])\n",
    "        print(valid, end = \", \")\n",
    "        if valid not in [0,1,-1,2]:\n",
    "            print(\"not 0 or 1\")\n",
    "        elif valid == -1:\n",
    "            i += 1\n",
    "            break\n",
    "        elif valid == 2:\n",
    "            i += 1\n",
    "            continue\n",
    "        elif valid in [0,1]:\n",
    "            dic[\"news\"].append(valid)\n",
    "            dic[\"txt\"].append(text)\n",
    "            dic[\"IstALIAS\"].append(Ist_ocurrence(text, aliases))\n",
    "            dic[\"countALI\"].append(count_alises(aliases, text))\n",
    "            dic[\"propAN\"].append(proportion_alphanumeric(text))\n",
    "            dic[\"countDTS\"].append(count_dates(text))\n",
    "            dic[\"txtSZ\"].append(text_size(text))\n",
    "            dic[\"countCAPS\"].append(count_CAPS(text))\n",
    "            i += 1\n",
    "    pd.DataFrame(dic).to_csv(out_name)\n",
    "    print(f\"\\n{i}\")\n",
    "\n",
    "# (0,2) (1,2) (3,4) (2,6) (1,6) (1,7) (3,3) (1,3) (4,1) (0,1) (4,6) (3,1) (1,4) (3,7)\n",
    "line, year = 3, 7\n",
    "aliases = df.iloc[line,0]\n",
    "texts = [i[\"ExtractedText\"] for i in df.iloc[line,year]]\n",
    "\n",
    "#dataset_create(aliases, texts, \"logreg_sonae2018.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ao fazer merge dos csv:\n",
    "\n",
    "- criar coluna com o ano e depois separar em até 2008, depois de 2009 até 2014, depois de 2015 aka 7 em 7 anos\n",
    "\n",
    "    - associar isto à prop de alfanumericos, por causa da publicidade ?\n",
    "\n",
    "acresencar features:\n",
    "\n",
    "- DONE ~~**titulo:** any alias in the first 50? char OU em q % de texto aparece o primeiro alias~~\n",
    "\n",
    "- DONE **links:** quantidade de links externos, contar \"http\"\n",
    "\n",
    "- DONE **horas:** quantidade de horas que aparecem \"hh:mm\"\n",
    "\n",
    "- ~~**fonte:** nos primeiros 50? caracteres ou nos finais, ver se diz rtp, publico, dn , etc. - vai ser variavel categorica, hot encoding~~\n",
    "\n",
    "    - associar esta binaria ao tamanho do texto com multiplicacao\n",
    "\n",
    "    - atencao q pode ter mais q rtp, publico no mesmo, pode se escolher o primeiro q aparecer\n",
    "\n",
    "    - caso nao tenha nenhum, chamar unknokn\n",
    "\n",
    "    - associar ao titulo, pq titulos sao diferentes consoante jornais\n",
    "\n",
    "ideia:\n",
    "\n",
    "e se fizer treedecision em vez de logistical regression ? CUIDADO COM OVERFITTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge all csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "csvs = [(x, x[-8:-4]) for x in os.listdir() if x[:7] == \"logreg_\"]\n",
    "dfs = []\n",
    "for csv, year in csvs:\n",
    "    df = pd.read_csv(csv, index_col=0)\n",
    "    df[\"year\"] = year\n",
    "    dfs.append(df)\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "\"\"\"\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_HTTP(text):\n",
    "    matches = re.findall(\"http\", text.lower())\n",
    "    return len(matches)\n",
    "\n",
    "def count_time_occurrences(text):\n",
    "    time_pattern = r'\\b([01]?[0-9]|2[0-3]):[0-5][0-9]\\b'   \n",
    "    occurrences = re.findall(time_pattern, text)\n",
    "    return len(occurrences)\n",
    "\n",
    "\"\"\"\n",
    "final_df[\"countHOUR\"] = final_df[\"txt\"].map(lambda x: count_time_occurrences(x))\n",
    "final_df[\"countHTTP\"] = final_df[\"txt\"].map(lambda x: count_HTTP(x))\n",
    "\n",
    "final_df\n",
    "\"\"\"\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.to_csv(\"logreg.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcdProj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
